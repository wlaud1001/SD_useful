{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b214b2f9-4b8f-4247-8723-b68c5382c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlaud1001/miniconda3/envs/diffusers/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from inverseSD import inverseSD\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c0af68-f034-4fc7-8162-b3bc390d64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7d45e9-ea55-49e3-8314-13ba874c09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16, use_auth_token=True).to(device)\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_xformers_memory_efficient_attention()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865350eb-8396-4d33-8cf6-7f1a77eaec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewAttnProcessor:\n",
    "    r\"\"\"\n",
    "    Processor for performing attention-related computations.\n",
    "    Save attention map\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        attn: Attention,\n",
    "        hidden_states,\n",
    "        encoder_hidden_states=None,\n",
    "        attention_mask=None,\n",
    "        temb=None,\n",
    "    ):\n",
    "        residual = hidden_states\n",
    "\n",
    "        if attn.spatial_norm is not None:\n",
    "            hidden_states = attn.spatial_norm(hidden_states, temb)\n",
    "\n",
    "        input_ndim = hidden_states.ndim\n",
    "\n",
    "        if input_ndim == 4:\n",
    "            batch_size, channel, height, width = hidden_states.shape\n",
    "            hidden_states = hidden_states.view(batch_size, channel, height * width).transpose(1, 2)\n",
    "\n",
    "        batch_size, sequence_length, _ = (\n",
    "            hidden_states.shape if encoder_hidden_states is None else encoder_hidden_states.shape\n",
    "        )\n",
    "        attention_mask = attn.prepare_attention_mask(attention_mask, sequence_length, batch_size)\n",
    "\n",
    "        if attn.group_norm is not None:\n",
    "            hidden_states = attn.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        query = attn.to_q(hidden_states)\n",
    "\n",
    "        if encoder_hidden_states is None:\n",
    "            encoder_hidden_states = hidden_states\n",
    "        elif attn.norm_cross:\n",
    "            encoder_hidden_states = attn.norm_encoder_hidden_states(encoder_hidden_states)\n",
    "\n",
    "        key = attn.to_k(encoder_hidden_states)\n",
    "        value = attn.to_v(encoder_hidden_states)\n",
    "\n",
    "        query = attn.head_to_batch_dim(query)\n",
    "        key = attn.head_to_batch_dim(key)\n",
    "        value = attn.head_to_batch_dim(value)\n",
    "\n",
    "        attention_probs = attn.get_attention_scores(query, key, attention_mask)\n",
    "        self.attention_probs = attention_probs\n",
    "        \n",
    "        hidden_states = torch.bmm(attention_probs, value)\n",
    "        hidden_states = attn.batch_to_head_dim(hidden_states)\n",
    "\n",
    "        # linear proj\n",
    "        hidden_states = attn.to_out[0](hidden_states)\n",
    "        # dropout\n",
    "        hidden_states = attn.to_out[1](hidden_states)\n",
    "\n",
    "        if input_ndim == 4:\n",
    "            hidden_states = hidden_states.transpose(-1, -2).reshape(batch_size, channel, height, width)\n",
    "\n",
    "        if attn.residual_connection:\n",
    "            hidden_states = hidden_states + residual\n",
    "\n",
    "        hidden_states = hidden_states / attn.rescale_output_factor\n",
    "\n",
    "        return hidden_states\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
